\chapter{Implementation}
The Links compiler is a multi-pass compiler with several distinct phases.
Coarsely, we can divide the compiler into two major components the front-end and back-end.
We can further subdivide the front-end into
\begin{itemize}
  \item Parser: Transforms the input source into a syntax tree.
  \item Early desugar: Performs source-to-source transformations before source analysis.
  \item Type checker: Analyses the source, performs type inference, and ensures terms are well-typed.
\end{itemize}
The compiler has more front-end components, but these are the most relevant for our implementation.
Similarly, the back-end can be further subdivided
\begin{itemize}
  \item IR Compiler: Transforms the source into an intermediate representation used by the interpreter.
  \item Pattern-matching compiler: Aids the IR compiler by compiling pattern-matching constructs into the intermediate representation.
\end{itemize}
Figure \ref{fig:compiler-phases} provides a high level picture of how the different relevant phases are connected. The subsequent sections discuss implementation specific details.
\begin{figure}[t]
\begin{center}
\tikzset{my ellipse/.style={
        draw=blue, 
        ultra thick, 
        rectangle, 
        anchor=west, 
        xshift=1.0cm},
}
\tikzset{my rectangle/.style={
        draw=black, 
        thick, 
        rectangle, 
        minimum width={width("Early desugar")+2pt}}
}
\tikzset{my arrow/.style={-latex, thick}}

\begin{tikzpicture}  
  % Frontend
  \node [my rectangle,draw=black,thick] (Early desugar) at (0,0) {Early desugar};
  \node [my rectangle,draw=black,thick,above of=Early desugar] (Parser) {Parser};
  \node [my rectangle,draw=black,thick,below of=Early desugar] (Typechecker) {Type checker};
  %\node [my rectangle,draw=black,thick,below of=Typechecker] (Late desugar) {Late desugar};

  \node[rectangle,draw=black,ultra thick,minimum height=+5.0cm,minimum width=+4.0cm,fit ={(Parser.north) (Typechecker.south)}] (Frontend) {};

  % Input source
  \node [rectangle,draw=black,thick,xshift=-3.0cm,left of=Frontend] (Source) {Source};

  % Backend
  \node [my rectangle,xshift=+4.0cm,draw=black,thick,right of=Parser] (Sugartoir) {IR Compiler};
  \node [my rectangle,yshift=-0.5cm,draw=black,thick,below of=Sugartoir] (PMC) {\begin{tabular}{l}Pattern\\Matching\\ Compiler\end{tabular}};
  
  \node[rectangle,draw=black,ultra thick,minimum width=+4.0cm,minimum height=+5.0cm,fit ={(Sugartoir.north) (PMC.south)}] (Backend) {};

  % Interpreter
  \node [rectangle,xshift=+3.5cm,draw=black,thick,right of=Backend] (Evalir) {Interpreter};

  % Texts
  \node [anchor=north, font=\bfseries,yshift=-0.1cm] at (Frontend.north) {Frontend};
  \node [anchor=north, font=\bfseries,yshift=-0.1cm] at (Backend.north) {Backend};

  % Arrows
  \draw [->, ultra thick] (Source.east) -- (Frontend.west) {};
  \draw [->, ultra thick] (Frontend.east) -- (Backend.west) {};
  \draw [->, ultra thick] (Backend.east) -- (Evalir.west) {};

  \draw [->, thick] (Parser.south) -- (Early desugar.north) {};
  \draw [->, thick] (Early desugar.south) -- (Typechecker.north) {};

  \draw [->, thick,out=150, in=20] (Sugartoir.-10.-150) -- (PMC.135.0) {};
  \draw [->, thick] (PMC.43.0) -- (Sugartoir.-19.0) {};
\end{tikzpicture}
\caption{Links compiler phases overview.}\label{fig:compiler-phases}
\end{center}
\end{figure}

\section{Early desugaring of handlers}
The \code{handler} and \code{open handler} constructs are syntactic sugar. They get desugared into a legacy construct from an early implementation. The initial implementation used a \code{handle}-construct for handlers. Figure \ref{fig:closedhandler-desugar} displays the conceptual transformation of \code{handler} to \code{handle}. 
This desugaring takes place right after the parsing phase. The early desugaring is beneficial because it allows us to take full advantage of the earlier implementation, whilst providing a more convenient syntax for handlers.
\begin{figure}[h]
    \centering
    \begin{subfigure}[c]{0.45\textwidth}
        \centering
\begin{lstlisting}[style=links]
handler(m) {
  case Op§*$_i$*§(p§*$_i$*§,k§*$_i$*§) -> b§*$_i$*§
  case Return(x) -> b
}
\end{lstlisting}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[c]{0.1\textwidth}
      $\Rightarrow$
    \end{subfigure}%
    ~
    \begin{subfigure}[c]{0.45\textwidth}
        \centering
\begin{lstlisting}[style=links]
fun(m) {
  handle(m) {
    case Op§*$_i$*§(p§*$_i$*§,k§*$_i$*§) -> b§*$_i$*§
    case Return(x) -> b
  }
}
\end{lstlisting}
    \end{subfigure}
\caption{The \code{handler}-construct gets desugared into a \code{handle}-construct where the computation $m$ is abstracted over using a function.}\label{fig:closedhandler-desugar}
\end{figure}

The \code{open handler}-constructs get desugared in a similar fashion, but, with a small twist: The \code{handle}-construct gets wrapped inside a thunk. The extra layer of indirection entailed by this transformation is \emph{the key} to make handlers composable. The crucial insight is that by transforming every open handler into a thunk compositionality follows for free because computations are modelled as thunks.
Figure \ref{fig:openhandler-desugar} shows the conceptual transformation for \code{open handler}-constructs.

\begin{figure}[h]
    \centering
    \begin{subfigure}[c]{0.45\textwidth}
        \centering
\begin{lstlisting}[style=links]
open handler(m) {
  case Op§*$_i$*§(p§*$_i$*§,k§*$_i$*§) -> b§*$_i$*§
  case Return(x) -> b
}
\end{lstlisting}        
    \end{subfigure}%
    ~ 
    \begin{subfigure}[c]{0.1\textwidth}
      $\Rightarrow$
    \end{subfigure}%
    ~
    \begin{subfigure}[c]{0.45\textwidth}
        \centering
\begin{lstlisting}[style=links]
fun(m) {
  fun() {
    handle(m) {
      case Op§*$_i$*§(p§*$_i$*§,k§*$_i$*§) -> b§*$_i$*§
      case Return(x) -> b
    }
  }
}
\end{lstlisting}       
    \end{subfigure}
\caption{The \code{open handler}-construct gets desugared into a thunked \code{handle}-construct.}\label{fig:openhandler-desugar}
\end{figure}

\section{Type inference}
\section{Pattern-matching compilation}
Syntactically, the \code{handler}-construct and \code{switch}-construct are similar. Figure \ref{fig:handler-switch} puts the two construct side-by-side.
\begin{figure}[h]
    \centering
    \begin{subfigure}[c]{0.45\textwidth}
        \centering
\begin{lstlisting}[style=links]
handler(m) {
  case Op§*$_i$*§(p§*$_i$*§,k§*$_i$*§) -> b§*$_i$*§
  case Return(x) -> b
}
\end{lstlisting}        
    \end{subfigure}%  
    ~
    \begin{subfigure}[c]{0.45\textwidth}
        \centering
\begin{lstlisting}[style=links]
switch(e) {
  case §*$\textit{Pattern}_j$*§ -> b§*$_j$*§
  case other   -> b§*$'$*§
}
\end{lstlisting}       
    \end{subfigure}
\caption{The \code{handler}-construct resembles the \code{switch}-construct syntactically.}\label{fig:handler-switch}
\end{figure}
Notably, their semantics differ as \code{switch} allows arbitrary pattern matching on an expression $x$ and \code{handler} only allows pattern matching on possible operation names in some computation $m$. Furthermore, \code{switch} has a default case \code{other} which is not allowed in \code{handler}. 
Their syntactic similarities give rise to a similar internal representation as well. Although, the internal representation of \code{handler} contains extra attributes such as whether the handler is open or closed.
The resemblance has certain benefits:
\begin{itemize}
  \item Syntactical commonalities makes handlers feel like a natural integrated part in Links,
  \item and we can reuse the \code{switch} pattern-matching compilation infrastructure for \code{handler}.
\end{itemize}
The \code{switch} pattern-matching compiler supports deep pattern-matching which we want for matching on actual operation parameters, but only a handful of patterns are permitted for matching on continuation parameters. Figure \ref{fig:cont-pattern-matching} shows the legal pattern-matching for the continuation parameter. Moreover, the \code{Return}-case must only take one parameter. These small subtleties prevent us from using the \code{switch} pattern-matching compiler directly.

\begin{figure}[H]
\begin{center}
\begin{lstlisting}[style=links]
         handler(m) {
           case Op§*$_i$*§(_,k)  -> b§*$_i$*§      # Name binding
           case Op§*$_j$*§(_,k as c) -> b§*$_j$*§  # Aliasing
           case Op§*$_l$*§(_,_)  -> b§*$_l$*§      # Wildcarding
           case Return(x) -> b
         }
\end{lstlisting}        
\end{center}
\caption{Permissible patterns for matching on the continuation parameter.}\label{fig:cont-pattern-matching}
\end{figure}

Instead we embed the \code{switch} pattern-matching compiler along with a preliminary pattern-matching analyser in the \code{handler} pattern-matching compiler. The pattern-matching analyser checks that the patterns are legal, i.e.
\begin{itemize}
  \item An operation-case has at least two parameters, where the last parameter is supposed to be the continuation.
  \item Pattern-matching on a continuation parameter is either name binding, aliasing or wildcarding.
  \item \code{Return}-case(s) only take one parameter.
\end{itemize}
If the pattern-matching analysis is successful then the \code{switch} pattern matching compiler is invoked to generate the code. Otherwise, a compilation error, complaining about illegal patterns, is emitted.

\section{Interpreter}
% Continuation passing style (CPS) is often used as an intermediate representation during the optimisation stage by functional compilers. In particular, CPS makes it easy to implement first-class control in the source level as CPS exposes the current continuation \cite{Appel2007}.

% A related intermediate representation is A-Normal Form (ANF) which is used by the Links compiler. Furthermore, the Links interpreter directly interprets ANF code \cite{Lindley2012}.
% ANF is a relatively simple language that enjoys many of the same advantages as CPS such as explicit exposure of the current continuation \cite{Flanagan1993}. However, CPS is better for performing optimisations, but the simpler nature of ANF makes it amendable as an interpreted language \cite{Appel2007,Flanagan1993}. 
The Links compiler uses A-Normal Form (ANF) as an intermediate representation. In particular, the Links interpreter directly interprets ANF code.
ANF is a relatively simple direct-style language which makes it easy to implement first-class control in the source language \cite{Flanagan1993}. Furthermore, a \code{let} construct assigns names to every intermediate computation, hence, it is in some sense equivalent to the imperative intermediate representation Static Single Assignment form \cite{Flanagan1993}. Its simple nature makes it amendable as an interpreted language.

The Links ANF partitions expressions into two classes: atomic expressions and complex expressions. An expression is considered atomic if it is pure, i.e. it terminates and causes no effects. A complex expression must be \code{let}-bound. For example the expression \code{g(f(x))} gets translated into the bound expression \code{let z = f(x) in g(z)}.


The original Links interpreter directly threaded the current continuation through the program. The continuation was implemented as a stack of continuation frames. A continuation frame is quadruple $(\mathcal{S},\mathcal{B},\mathcal{E},\mathcal{C})$ where
\begin{itemize}
  \item $\mathcal{C}$ is a computation.
  \item $\mathcal{E}$ is an environment that binds names in $\mathcal{C}$ to values.
  \item $\mathcal{B}$ is a binder for the computation.
  \item $\mathcal{S}$ denotes the scope of the computation.
\end{itemize}
