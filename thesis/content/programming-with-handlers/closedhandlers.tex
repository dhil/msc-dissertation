\section{Closed handlers}\label{sec:closedhandlers}
A handler assigns semantics to abstract operations. In Links, this is reflected in the syntax as a handler embodies a collection of pattern-matching cases, which map operation names to computations, e.g.
\begin{lstlisting}[style=links]
handler h(m) {
  case Op(p,k)   -> §*$m_{\code{Op}}$*§
  case Return(x) -> §*$m_{\code{Return}}$*§
}
\end{lstlisting}
In the previous section we said that every operation takes exactly one argument, yet, an operation \code{Op$_i$}-case matches on two parameters. The first parameter \code{p} is the operation argument, whilst the second parameter \code{k} exposes a delimited continuation that accepts a single parameter. Invocation of continuation transfers control back to the handled computation \code{m} at the point where the said operation was discharged. Both parameters may be referenced multiple times in the case-computation $m_{\code{Op}}$.
There may be a variable number of operation-cases, however, there must be at least one \code{Return}-case in every handler. The \code{Return}-case is a special case that is implicitly invoked when the handled computation \code{m} finishes. The purpose of \code{Return} is discussed in Section \ref{sec:transform}.

The formal parameter \code{m} is a name for the abstract computation which the handler interprets. Because Links employ a strict evaluation strategy computations are modelled as thunks, that is, the type of \code{m} is $() \xrightarrow{E} b$ where $E$ is the set of operations that \code{m} may discharge.

\subsection{Typing closed handlers}
A closed handler handles a fixed set of effects, that is, it puts an upper bound on which kind of effects a computation may perform. In Links this bound is made explicit in the handler's type, e.g. closed handler \code{h} above has the following type
\[ (() \xrightarrow{ \{\type{Op}: a_1 \to a_2 \}\;} b) \to c \]
where $b$ is the return type of the computation \code{m}, and $c$ is the type of $m_{\code{Return}}$.
The absence of a row variable in the effect signature implies that the computation \code{m} may not perform any other effects than \type{Op}. It is considered a type error to attempt to handle a computation whose effect signature is not unifiable with the formal parameter \code{m}'s effect signature.

This restriction introduces slack into the type system \cite{Huttel2010}. To illustrate the slack consider the following computation
\begin{lstlisting}[style=links]
fun comp() {
  do Op(true);
  if (false == true) { do Op2(false) }
  else { true }
}
\end{lstlisting}
The computation \code{comp} has type $\thunktype{Op:\type{Bool} \to (),Op2:\type{Bool} \to \type{Bool} \; | \; \rho}{\type{Bool}}$. Obviously, \code{Op2} never gets discharged. However, attempting to handle \code{comp} with the handler \code{h} gives rise to the following unsolvable equation 
\[ \{\type{Op}: a_1 \to a_2\} \sim \{\type{Op}:\type{Bool} \to (),\type{Op2}:\type{Bool} \to \type{Bool} \; | \; \rho \}\]
There is no solution as we cannot shrink rows.

The following sections will show increasingly interesting examples of programming with closed handlers in Links.

\subsection{Transforming the results of computations}\label{sec:transform}
The first two examples show how to transform the output of a computation using handlers. We begin with a handler that appears to be rather boring, but in fact proves very useful as we shall see later in Section \ref{sec:openhandlers}.
\begin{example}[The force handler]\label{ex:force}
We dub the handler \code{force} as it takes a computation (thunk) as input, evaluates it and returns its result. It has type $(() \to a) \to a$ and it is defined as
\begin{lstlisting}[style=links]
var force = handler(m) {
    case Return(x) -> x
}
\end{lstlisting}
Essentially, this handler applies the identity transformation to the result of the computation \code{m}. Running \code{force} on a few examples should yield no surprises:
\begin{lstlisting}[style=links]
fun fortytwo() { 42 }
links> force(fortytwo);
42 : Int

fun hello() { "Hello" }
links> force(hello);
"Hello" : String
\end{lstlisting}
The handler \code{force} behaves as expected for these trivial examples. The \code{force} also runs side-effecting computations:
\begin{lstlisting}[style=links]
links> force(fun() { print("Hello World") });
"Hello World"
() : ()
\end{lstlisting}
The \code{force} handler's effect row implicitly contains the wild effect. Without the presence of the wild effect closed handlers would not be have to run computations that might diverge. Moreover, many of the higher-order functions in Links have non-empty effect rows. Thus not allowing the wild effect severely limits the class of computations that a closed handler can handle.
\end{example}

The next example demonstrates an actual transformation.
\begin{example}[The listify handler]\label{ex:listify}
The \code{listify} handler transforms the result of a handled computation into a singleton list. Its type is $ (() \to a) \to [a]$ and its definition is straightforward
\begin{lstlisting}[style=links]
handler listify(m) {
  case Return(x) -> [x]
}
\end{lstlisting}
Running it on a few examples we obtain:
\begin{lstlisting}[style=links]
links> listify(fortytwo);
[42] : [Int]
links> listify(hello);
["Hello"] : [String]
links> listify(fun() { [1,2,3] });
[[1,2,3]] : [[Int]]
\end{lstlisting}
This example also illustrates that the \code{Return}-case serves a similar purpose to the monadic \code{return}-function in Haskell whose type is $\code{return} : a \to m\, a$ for a monad $m$. It ``lifts'' a value into a monadic value, similarly, the \code{Return}-case lifts a value into a ``handled'' value.
\end{example}

In a similar fashion to the handler \code{listify} in Example \ref{ex:listify} we can define handlers that increment results by 1, perform a complex calculation using the result of the computation or wholly ignore the result. However, it must ensure that the type of the output is compatible with the output type of the handler. In the case for \code{listify} the output must be a list of whatever the computation yielded.

\subsection{Exception handling}\label{sec:maybehandler}
Until now we have only seen some simple transformations. Let us make things more interesting.
Example \ref{ex:maybe} introduces our first practical handler \code{maybe}. It is similar to the \type{Maybe}-monad in Haskell. For reference we briefly sketched the behaviour of the \type{Maybe}-monad in Section \ref{sec:problem-with-monads}.
\begin{example}[The maybe handler]\label{ex:maybe}
The \type{maybe} handler handles one operation $\type{Fail} : a_1 \to a_2$ that can be used to indicate that something unexpected has happened in a computation. The handler returns \type{Nothing} when \type{Fail} is raised, and \type{Just} the result when the computation succeeds, thus its type is
\[ \chntype{\thunktype{\type{Fail} : a_1 \to a_2}{b}}{\type{Maybe}(b)}. \]
It is defined as
\begin{lstlisting}[style=links]
handler maybe(m) {
  case Fail(_,_) -> Nothing
  case Return(x) -> Just(x)
}
\end{lstlisting}
When a computation discharges \type{Fail} the handler discards the remainder of the computation and returns \type{Nothing} immediately, e.g.
\begin{lstlisting}[style=links]
fun yikes() { 
  var x = "Yikes!";
  do Fail();
  x
}
links> maybe(yikes);
Nothing() : Maybe(String)
\end{lstlisting}
and if the computation succeeds it transforms the result, e.g.
\begin{lstlisting}[style=links]
fun success() {
  true
}
links> maybe(success);
Just(true) : Maybe(Bool)
\end{lstlisting}
\end{example}
% The next example demonstrates an alternative ``exception handling strategy''.
% \begin{example}[The recover handler]\label{ex:recover}
% We can define a handler \code{recover} which ignores the raised exception and resumes execution of the computation.
% The type of \code{recover} is
% \[ \code{recover} : \chntype{\thunktype{\type{Fail}: a \to ()}{b}}{[|\type{Just}:b|\rho|]}. \]
% A slight reminder here: The label \type{Nothing} is absent from the handler's output type because \type{Just} is a polymorphic variant label and its relation to \type{Nothing} is conventional. We define \code{recover} as
% \begin{lstlisting}[style=links]
% var recover = handler(m) {
%   case Fail(_,k) -> k(())
%   case Return(x) -> Just(x)
% }
% \end{lstlisting}
% In contrast to \code{maybe} from Example \ref{ex:maybe} the \code{recover} handler invokes the continuation \code{k} once. This invocation effectively resumes execution of the computation. Consider \code{recover} applied to the computation \code{yikes} from before
% \begin{lstlisting}[style=links]
% links> recover(yikes)
% Just("Yikes!") : [|Just:String|§*$\rho$*§|]
% \end{lstlisting}
% \end{example}
% Although it is seldom a sound strategy to ignore exceptions the two Examples \ref{ex:maybe} and \ref{ex:recover} demonstrate that we can change the semantics of the computation by changing the handler.

\subsection{Handling choice}\label{sec:choice}
In Section \ref{sec:effects-as-computation-trees} we visualised some interpretations the abstract computation
\begin{lstlisting}[style=links]
fun choice() {
  if (do Choose()) {
    if (do Choose()) { 2 }
    else { 4 }
  } else {
    if (do Choose()) { 8 }
    else { 16 }
}
\end{lstlisting}
which uses the operation $\type{Choice} : () \to \type{Bool}$. For completeness we show how to implement these interpretations in Links. Example \ref{ex:positive} shows the positive interpretation and Example \ref{ex:enumerate} shows the enumeration interpretation.
\begin{example}\label{ex:positive}
Whenever the operation \type{Choose} is discharged in the computation \code{choice} the handler has to decide whether to pick \code{true} or \code{false}. Therefore the type of the handler \code{positive} must be
$(() \xrightarrow{\{\type{Choose}:() \to \type{Bool}\}\;} a) \to a$.
The \code{positive} handler always picks \code{true}, in other words, the continuation is always invoked with the parameter \code{true}, e.g.
\begin{lstlisting}[style=links]
handler positive(m) {
  case Choose(_,k) -> k(true)
  case Return(x)   -> x
}
\end{lstlisting}
Running the handler on the computation \code{choice} yields the expected result:
\begin{lstlisting}[style=links]
links> positive(choice);
\end{lstlisting}
The definition of the handler \code{negative} from Section \ref{sec:effects-as-computation-trees} is analogous to \code{positive}.
\end{example}

\begin{example}\label{ex:enumerate}
The handler \code{enumerate} traverses the entire computation tree as shown in Figure \ref{fig:enumerate}. Therefore, when \type{Choose} is discharged the handler has to invoke the continuation twice. First time with \code{true} and the second time with \code{false}. In particular, the handler must collect the results in a list, so the type of \code{enumerate} is 
$(() \xrightarrow{\{\type{Choose}:() \to \type{Bool}\}\;} a) \to [a]$.
The computation returns a single element, therefore we have to use the \code{Return}-case to lift that element into a singleton list. Hence two invocations of the continuation give us two lists which we can join together to form a single list, e.g.
\begin{lstlisting}[style=links]
handler enumerate(m) {
  case Choose(_,k) -> k(true) ++ k(false)
  case Return(x)   -> [x]
}
\end{lstlisting}
Applying \code{enumerate} to the computation \code{choice} yields the result we arrived at in Section \ref{sec:effects-as-computation-trees}:
\begin{lstlisting}[style=links]
links> enumerate(choice);
[2, 4, 8, 16] : [Int]
\end{lstlisting}
\end{example}

\subsection{Interpreting Nim}\label{sec:interpreting-nim}
Nim is a well-studied mathematical strategic game, and probably among the oldest of its kind \cite{Joergensen2009}. In Nim two players take turns to pick between one and three sticks from heaps of sticks. Whoever takes the last stick wins. This play style is also known as \emph{normal play}. 

Nim enjoys many interesting game theoretic properties, however we will use a simplified version of Nim to demonstrate how handlers can give different interpretations of the same game. In our simplified version there is only one heap of $n$ sticks. Moreover, there are two players: Alice and Bob, and Alice always starts. Our model is adapted from Kammar et. al \cite{Kammar2013}.

We model the game as two mutual recursive abstract computations, e.g.
\begin{lstlisting}[style=links]
# Input n is the number of remaining sticks
fun aliceTurn(n) {
  if (n == 0) {
    Bob
  } else {
    var take = do Move((Alice,n));
    var r = n - take;
    bobTurn(r)
  }
}

# Symmetrically for Bob
fun bobTurn(n) {
  if (n == 0) {
    Alice
  } else {
    var take = do Move((Bob,n));
    var r = n - take;
    aliceTurn(r)
  }
}
\end{lstlisting}
The two computations are symmetrical. The input parameter \code{n} is the number of sticks left in the heap. First, Alice tests whether there are any sticks left, if there is not then she declares \type{Bob} the winner, otherwise she performs her move and then she gives the turn to Bob.
The game has one abstract operation \code{Move} which has the inferred type $\code{Move} : ([|\type{Alice}|\type{Bob}|\rho|], \type{Int}) \to \type{Int}$, i.e. it takes two arguments
\begin{enumerate}
  \item Who's turn it is,
  \item and the number of remaining sticks.
\end{enumerate}
The operation \code{Move} returns the number of sticks that the current player takes. Figure \ref{fig:nim-comp-tree} depicts the shape of the computation tree representation of the game.
\begin{figure}[H]
  \begin{center}
  Tree
  \end{center}
  \caption{Nim game computation tree}\label{fig:nim-comp-tree}
\end{figure}
The depth of the tree is potentially infinite as the depth depends entirely on the interpretation of the operation \code{Move}. The inferred type of a game is
\[ \code{aliceTurn}: \type{Int} \xrightarrow{\type{Move}:([|\type{Alice}|\type{Bob}|\rho|],\type{Int}) \to \type{Int}\;} [|\type{Alice}|\type{Bob}|\rho|] \]
Because it is an unary function it cannot be used as an input to any handler. We rectify the problem by using a closure, i.e. we wrap the game function inside a nullary function like \code{fun()$\{$aliceTurn(n)$\}$} where \code{n} is a free variable captured by the surrounding context.
For conveniency, we define an auxiliary function \code{play} to abstract away these details. It takes as input a game handler \code{gh} and the number of sticks at the beginning of game \code{n}. Moreover, the function \code{play} enforces the rule that Alice always starts, e.g.
\begin{lstlisting}[style=links]
fun play(gh, n) {
  gh(fun() {
      aliceTurn(n)
    })
}
\end{lstlisting}
The following examples demonstrates how handlers encode the strategic behaviour of the players.
\begin{example}[A naïve strategy]\label{ex:nim-naive}
A very naïve strategy is to pick just \emph{one} stick at every turn.
Its implementation is straightforward
\begin{lstlisting}[style=links]
var naive = handler(m) {
  case Move(_,k) -> k(1)
  case Return(x) -> x
};
\end{lstlisting}
Here \code{Move} is handled uniformly. Independent of the parameterisation it always invokes the continuation \code{k} with 1 which corresponds to the player taking just 1 stick from the heap.

A moment's thought will tell us that we can easily predict the winner when using the \code{naive} strategy. The parity of $n$, the number of sticks at the beginning, determines the winner. For odd $n$ Alice wins and vice versa for even $n$, e.g.
\begin{lstlisting}
links> play(naive, 5);
Alice() : [|Alice|Bob|§*$\rho$*§|]

links> play(naive, 10);
Bob() : [|Alice|Bob|§*$\rho$*§|]

links> play(naive, 101);
Alice() : [|Alice|Bob|§*$\rho$*§|]
\end{lstlisting} 
\end{example}

\begin{example}[Perfect vs perfect strategy]\label{ex:nim-perfect}
A perfect strategy makes an optimal move at each turn. An optimal move depends on the remaining number of sticks $n$. The perfect move can be defined as a function of $n$, e.g.
\[ \text{perfect}(n) = \max\{n\; \text{mod}\; 4, 1\} \]
In our restricted Nim game a perfect strategy is a winning strategy for Alice if and only if the number of remaining sticks is \emph{not} divisible by 4.

We implement the function \code{perfect} above with an addition: We pass it a continuation as second parameter
\begin{lstlisting}[style=links]
fun perfect(n, k) {
  k(max(mod(n,4),1))
}
\end{lstlisting}
The continuation is invoked with the optimal move. Now we can easily give a handler that assigns perfect strategies to both Alice and Bob, e.g.
\begin{lstlisting}[style=links]
var pvp = handler(m) {
  case Move((_,n),k) -> perfect(n, k)
  case Return(x)     -> x
};
\end{lstlisting}
By running some examples we see that Alice wins whenever $n$ is not divisible by four:
\begin{lstlisting}[style=links]
links> play(pvp, 9);
Alice() : [|Alice|Bob|§*$\rho$*§|]

links> play(pvp, 18);
Alice() : [|Alice|Bob|§*$\rho$*§|]

links> play(pvp, 36);
Bob() : [|Alice|Bob|§*$\rho$*§|]
\end{lstlisting}
\end{example}

\begin{example}[Mixing strategies]\label{ex:nim-mixing}
A strategy often encountered in game theory is \emph{mixing} which implies a player randomises its strategies in order to confuse its opponent. In similar fashion to \code{perfect} from Example \ref{ex:nim-perfect} we define a function \code{mix} which chooses a strategy
\begin{lstlisting}[style=links]
fun mix(n,k) {
  var r = mod(nextInt(), 3) + 1;
  if (r > 1 && n >= r)) {
     k(r)
  } else {
     k(1)
  }
}
\end{lstlisting}
The function \code{nextInt} returns the next integer in some random sequence. The random integer is projected into the cyclic group $\mathbb{Z}_3 = \{0,1,2\}$ generated by $3$. We add one to map it onto the set of valid moves $\{1,2,3\}$. If the random choice \code{r} is greater than the number of remaining sticks \code{n} then we default to take one (even though the optimal choice might be to take two).

The \code{mixing} strategy handler is similar to perfect-vs-perfect handler from Example \ref{ex:nim-perfect}
\begin{lstlisting}[style=links]
var mixing = handler(m) {
    case Move((_,n),k) -> mix(n,k)
    case Return(x)     -> x			  
};
\end{lstlisting}
Replaying the same game a few times ought eventually yield the two possible outcomes
\begin{lstlisting}
links> play(mixing, 7);
Bob() : [|Alice|Bob|§*$\rho$*§|]

links> play(mixing, 7);
Alice() : [|Alice|Bob|§*$\rho$*§|]
\end{lstlisting}
\end{example}

\begin{example}[Brute force strategy]\label{ex:nim-brute-force}
Examples \ref{ex:nim-naive}-\ref{ex:nim-mixing} only invoked the continuation once per move. However, we can invoke the continuation multiple times to enumerate all possible future moves, this way we can brute force a winning strategy, if one exists. In order to brute force a winning strategy, we define a convenient utility function which computes the set of valid moves given the number of remaining sticks
\begin{lstlisting}[style=links]
fun validMoves(n) {
 filter(fun(m) { m <= n }, [1,2,3])
}
\end{lstlisting}
The function simply filters out impossible moves based on the current configuration $n$. Note when $n > 3$ the function \code{validMoves} behaves like the identity function.
The function \code{bruteForce} computes the winning strategy for a particular player if such a strategy exists:
\begin{lstlisting}[style=links]
fun bruteForce(player, n, k) {
  var winners = map(k, validMoves(n));
  var hasPlayerWon = indexOf(player, winners);
  switch (hasPlayerWon) {
     case Nothing -> k(1)
     case Just(i) -> k(i+1)
  }
}
\end{lstlisting}
The first line inside \code{bruteForce} is the critical point. Here we map the continuation \code{k} over the possible valid moves in the current game configuration. Thus the function effectively simulates all possible future configurations yielding a list of possible winners. The auxiliary function \code{indexOf} looks up the position of \code{player} in the list of winners. The position plus one corresponds to the winning strategy because lists indexes are zero-based. If the player has a winning strategy then the (zero-based) position is returned inside a \type{Just}, otherwise \code{Nothing} is returned.

Let Alice play the brute force strategy and let Bob play the perfect strategy which is captured by the strategy handler \code{bfvp}
\begin{lstlisting}[style=links]
var bfvp = handler(m) {
  case Move((Alice,n),k) -> bruteForce(Alice,n,k)
  case Move((Bob,n),k)   -> perfect(n,k)
  case Return(x)         -> x
};
\end{lstlisting}
Here we use deep pattern-matching to distinguish between when \type{Alice} and \type{Bob}'s moves. Obviously, the brute force strategy is inefficient as it redoes a lot of work for each move. The winning strategy that it discovers is exactly same as the perfect strategy. Albeit, \code{bruteForce} computes it in exponential time whilst \code{perfect} computes it in constant time. The following outcomes witness that \code{bruteForce} and \code{perfect} behaves identically
\begin{lstlisting}[style=links]
links> play(bfvp, 9);
Alice() : [|Alice|Bob|§*$\rho$*§|]

links> play(bfvp, 18);
Alice() : [|Alice|Bob|§*$\rho$*§|]

links> play(bfvp, 36);
Bob() : [|Alice|Bob|§*$\rho$*§|]
\end{lstlisting}
\end{example}
Although, the \code{bruteForce} strategy is significantly slower than \code{perfect} strategy in Example \ref{ex:nim-brute-force} the point of interest here is not efficiency but rather modularity. As Example \ref{ex:nim-brute-force} nicely demonstrates we can swap two observably equivalent handlers effortlessly. Clearly, this has practical applications for example one would be able to quickly create a prototypical system with slow but easy to implement components. Then later as the system scales one can change the slow components for a faster ones effortlessly.

Examples \ref{ex:nim-naive}-\ref{ex:nim-brute-force} gave different interpretations of the same game. Furthermore, the all computed the same thing, namely, the winner. We can use handlers to create data from computations. For example we can construct the game tree in a Nim game as Example \ref{ex:nim-game-tree} shows. 

\begin{example}[Game tree generator]\label{ex:nim-game-tree}
A node in a game tree represents a particular player's turn and an edge corresponds to a particular move. A path down the tree corresponds to a particular sequence of moves taken by the players ending in a leaf node which corresponds to the winner. Figure \ref{fig:ex-nim-game-tree} shows an example game tree when starting with 3 sticks.

Our game tree is a ternary tree which we represent using a recursive variant type, e.g.
\[ \type{MoveTree} \defas [|\type{Take}:(\type{Player},[(\type{Int},\type{MoveTree})])\,|\,\type{Winner}:\type{Player}|] \]
Actually, we will not use the type explicitly, but rather rely on Links' type inference. It will infer a polymorphic variant type rather than the monomorphic type given above.

We define a function \code{reifyMove} which takes a player, the number of sticks, and a continuation to construct a node in the game tree, e.g.
\begin{lstlisting}[style=links]
fun reifyMove(player, n, k) {
  var moves = map(k, validMoves(n));
  var interval = range(1,length(moves));
  Take(player, zip(interval, moves))
}
\end{lstlisting}
First, we map the continuation over the possible valid moves in the current game configuration to enumerate the subsequent game trees. The \code{interval} is a list of integers from one to the number of immediate subtrees. Finally, we construct a node \type{Take} with \code{player} and the possible subsequent game trees.

We determine the winner of a particular play in the \code{Return}-case of the handler, e.g.
\begin{lstlisting}[style=links]
var mtGen = handler(m) {
  case Move((player,n),k) -> reifyMove(player,n,k)
  case Return(x)          -> Winner(x)
};
\end{lstlisting}
The inferred type for \code{mtGen} witnesses that the handler indeed constructs a tree structure:
\[ \code{mtGen} : (() \xrightarrow{\{\type{Move}:(a,\type{Int}) \to \type{Int}\}\;} b) \to \mu\, c\, . \, [|\type{Take}:(a, [(\type{Int}, c)])|\type{Winner}:b|\rho|] \]
Figure \ref{fig:ex-nim-game-tree} depicts the game tree generated by the handler when starting with 3 sticks.
\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[level distance=1.5cm,
level 1/.style={sibling distance=3.5cm},
level 2/.style={sibling distance=2cm}]

\node (Root) [draw=none,rectangle] {Alice}
    child { node[draw=none] (q0) {Bob} 
      child { node[draw=none] {Alice}
        child { node[draw=none] {Alice wins}
          edge from parent node [draw=none,left,xshift=-2.3,yshift=2.3] {1}
        }
        edge from parent node [draw=none,left,xshift=-2.0,yshift=2.0] {1}
      }
      child { node[draw=none] {Bob wins}
        edge from parent node [draw=none,right,xshift=2.0,yshift=2.0] {2}
      }
      edge from parent node [draw=none,left,xshift=-2.0,yshift=2.0] {1}
    }
    child { node [draw=none] {Bob}
      child { node[draw=none] {Bob wins}
        edge from parent node [draw=none,right,xshift=2.0,yshift=2.0] {1}
      }
      edge from parent node [draw=none,right,xshift=2.0,yshift=2.0] {2}
    }
    child { node [draw=none] {Alice wins}
      edge from parent node [draw=none,right,xshift=2.0,yshift=2.0] {3}
    };    
\end{tikzpicture}
\end{center}
\caption{Pretty print of the game tree generated by \code{play(mtGen, 3)}.}\label{fig:ex-nim-game-tree}
\end{figure}
\end{example}